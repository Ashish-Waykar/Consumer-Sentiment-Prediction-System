{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWAB69mvruVm",
    "outputId": "48a51902-368f-485a-dbdb-9d889fda95af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: daal4py in c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2023.0.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from daal4py) (1.21.4)\n",
      "Requirement already satisfied: daal==2023.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from daal4py) (2023.0.1)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from daal==2023.0.1->daal4py) (2021.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install daal4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bzdt-UHps8Uh",
    "outputId": "4810f8ca-5808-4241-e9bb-cfcb45391bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7659837077264873\n",
      "Precision: 0.7312820512820513\n",
      "Recall: 0.6583564173591875\n",
      "F1-score: 0.6929057337220602\n",
      "New data predictions: [0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Ashish-Waykar/DSA/main/training_data_sentiment.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "df = df[['Headline', 'SentimentHeadline']]\n",
    "df['SentimentHeadline'] = df['SentimentHeadline'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Headline'], df['SentimentHeadline'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Define and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Evaluate the model's performance on the testing set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred))\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = ['Obama delivers speech at Democratic National Convention', 'Apple announces new iPhone models', 'Stock market crashes']\n",
    "new_data_vectorized = vectorizer.transform(new_data)\n",
    "new_data_pred = model.predict(new_data_vectorized)\n",
    "print('New data predictions:', new_data_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdmhiU88r-hi",
    "outputId": "55b6bbfe-a9f2-4bdb-a479-c06ba892b51c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device support is limited in daal4py patching. Use Intel(R) Extension for Scikit-learn* for full experience.\n"
     ]
    }
   ],
   "source": [
    "# daal4py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from daal4py.sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Ashish-Waykar/DSA/main/training_data_sentiment.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "df = df[['Headline', 'SentimentHeadline']]\n",
    "df['SentimentHeadline'] = df['SentimentHeadline'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Headline'], df['SentimentHeadline'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Define and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Evaluate the model's performance on the testing set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred))\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = ['Obama delivers speech at Democratic National Convention', 'Apple announces new iPhone models', 'Stock market crashes']\n",
    "new_data_vectorized = vectorizer.transform(new_data)\n",
    "new_data_pred = model.predict(new_data_vectorized)\n",
    "print('New data predictions:', new_data_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "nqKSzkcvtudy",
    "outputId": "019b24a1-de26-471f-9224-0b8417d02774"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot confusion matrix for test set\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fyyIFMlz7_on",
    "outputId": "057c7349-72e2-4002-8ac0-c352e0ec2b07"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from daal4py.sklearn.linear_model import LogisticRegression as daal_LogisticRegression \n",
    "from sklearn.linear_model import LogisticRegression as skl_LogisticRegression \n",
    "import time \n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Ashish-Waykar/DSA/main/training_data_sentiment.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "df = df[['Headline', 'SentimentHeadline']]\n",
    "df['SentimentHeadline'] = df['SentimentHeadline'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Headline'], df['SentimentHeadline'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to numerical features using CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "daal_start_time = time.time()\n",
    "# Define and train a logistic regression model using daal4py\n",
    "daal_model = daal_LogisticRegression()\n",
    "daal_model.fit(X_train_vectorized, y_train)\n",
    "daal_end_time = time.time()\n",
    "\n",
    "skl_start_time = time.time()\n",
    "# Define and train a logistic regression model using sklearn\n",
    "sk_model = skl_LogisticRegression()\n",
    "sk_model.fit(X_train_vectorized, y_train)\n",
    "skl_end_time = time.time()\n",
    "\n",
    "# Evaluate the performance of both models on the testing set\n",
    "daal_scores = [accuracy_score(y_test, daal_model.predict(X_test_vectorized)),\n",
    "               precision_score(y_test, daal_model.predict(X_test_vectorized)),\n",
    "               recall_score(y_test, daal_model.predict(X_test_vectorized)),\n",
    "               f1_score(y_test, daal_model.predict(X_test_vectorized))]\n",
    "\n",
    "sk_scores = [accuracy_score(y_test, sk_model.predict(X_test_vectorized.toarray())),\n",
    "             precision_score(y_test, sk_model.predict(X_test_vectorized.toarray())),\n",
    "             recall_score(y_test, sk_model.predict(X_test_vectorized.toarray())),\n",
    "             f1_score(y_test, sk_model.predict(X_test_vectorized.toarray()))]\n",
    "\n",
    "# Plot the results\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, daal_scores, width, label='daal4py')\n",
    "rects2 = ax.bar(x + width/2, sk_scores, width, label='sklearn')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "daal_time = daal_end_time - daal_start_time\n",
    "skl_time = skl_end_time - skl_start_time\n",
    "\n",
    "print(\"Time taken by daal4py model: {:.2f} seconds\".format(daal_time))\n",
    "print(\"Time taken by sklearn model: {:.2f} seconds\".format(skl_time))\n",
    "\n",
    "metrics = [ 'Time']\n",
    "daal_scores.append(daal_time)\n",
    "sk_scores.append(skl_time)\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, daal_scores, width, label='daal4py')\n",
    "rects2 = ax.bar(x + width/2, sk_scores, width, label='sklearn')\n",
    "\n",
    "ax.set_ylabel('Scores/Time (Seconds)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
